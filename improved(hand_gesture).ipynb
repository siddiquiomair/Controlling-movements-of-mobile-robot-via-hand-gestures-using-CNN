{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dc2b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import serial\n",
    "import time\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b71062d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5966 images belonging to 6 classes.\n",
      "Found 572 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('HD/train',target_size = (64, 64),batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('HD/test',\n",
    "                                             target_size = (64, 64),batch_size = 32,class_mode = 'binary')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19bdfabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "# Step 2 - Pooling\n",
    "classifier.add(BatchNormalization(axis=3))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization(axis=3))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization(axis=3))\n",
    "classifier.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization(axis=3))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 6, activation = 'softmax'))\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96d8ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "187/187 [==============================] - 58s 297ms/step - loss: 0.2734 - accuracy: 0.9212 - val_loss: 10.1407 - val_accuracy: 0.1696\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 41s 221ms/step - loss: 0.0545 - accuracy: 0.9874 - val_loss: 0.9683 - val_accuracy: 0.7465\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 41s 219ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.0227 - val_accuracy: 0.9965\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 41s 220ms/step - loss: 0.0436 - accuracy: 0.9883 - val_loss: 0.0197 - val_accuracy: 0.9965\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 41s 220ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0215 - val_accuracy: 0.9965\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 42s 224ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0766 - val_accuracy: 0.9948\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 41s 221ms/step - loss: 0.0222 - accuracy: 0.9935 - val_loss: 0.0504 - val_accuracy: 0.9930\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 41s 219ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0099 - val_accuracy: 0.9983\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 42s 222ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.0276 - val_accuracy: 0.9965\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 43s 229ms/step - loss: 0.0361 - accuracy: 0.9904 - val_loss: 0.0440 - val_accuracy: 0.9965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "r=classifier.fit(training_set,epochs = 10,validation_data = test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "698a4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "def write_read(x):\n",
    "    data =  arduino.write(bytes(x, 'utf-8'))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "71f41a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arduino = serial.Serial(port='COM4', baudrate=9600, timeout=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "589838a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global filename\n",
    "global classifier\n",
    "\n",
    "\n",
    "bg = None\n",
    "playcount = 0\n",
    "names = ['b', 'f', 'l', 'n', 'r', 's']\n",
    "bgModel = cv2.createBackgroundSubtractorMOG2(0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3428db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_avg(image, aWeight):\n",
    "    global bg\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return\n",
    "    cv2.accumulateWeighted(image, bg, aWeight)\n",
    "\n",
    "def segment(image, threshold=25):\n",
    "    global bg\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "    thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "    ( cnts, _) = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)\n",
    "\n",
    "\n",
    "def webcamPredict():\n",
    "    \n",
    "    oldresult = 'none'\n",
    "    nval=0\n",
    "    count = 0\n",
    "    fgbg2 = cv2.createBackgroundSubtractorKNN(); \n",
    "    aWeight = 0.5\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    top, right, bottom, left = 10, 350, 325, 690\n",
    "    num_frames = 0\n",
    "    while(True):\n",
    "        (grabbed, frame) = camera.read()\n",
    "        frame = imutils.resize(frame, width=700)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        clone = frame.copy()\n",
    "        (height, width) = frame.shape[:2]\n",
    "        roi = frame[top:bottom, right:left]\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (41, 41), 0)\n",
    "        if num_frames < 30:\n",
    "            run_avg(gray, aWeight)\n",
    "        else:\n",
    "            temp = gray\n",
    "            hand = segment(gray)\n",
    "            if hand is not None:\n",
    "                (thresholded, segmented) = hand\n",
    "                cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "                #cv2.imwrite(\"test.jpg\",temp)\n",
    "                #cv2.imshow(\"Thesholded\", temp)\n",
    "                #ret, thresh = cv2.threshold(temp, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                #thresh = cv2.resize(thresh, (64, 64))\n",
    "                #thresh = np.array(thresh)\n",
    "                #img = np.stack((thresh,)*3, axis=-1)\n",
    "                roi = frame[top:bottom, right:left]\n",
    "                roi = fgbg2.apply(roi); \n",
    "                cv2.imwrite(\"test.jpg\",roi)\n",
    "                #cv2.imwrite(\"newDataset/Fist/\"+str(count)+\".png\",roi)\n",
    "                #count = count + 1\n",
    "                #print(count)\n",
    "                \n",
    "                img = cv2.imread(\"test.jpg\")\n",
    "                img = cv2.resize(img, (64, 64))\n",
    "                img = img.reshape(1, 64, 64, 3)\n",
    "                img = np.array(img, dtype='float32')\n",
    "                img /= 255\n",
    "                \n",
    "                predict = classifier.predict(img)\n",
    "                value = np.amax(predict)\n",
    "                cl = np.argmax(predict)\n",
    "                result = names[np.argmax(predict)]\n",
    "                if value >= 0.99:\n",
    "                    if(result=='n' and nval<1):\n",
    "                        print(str(value)+\" \"+str(result))\n",
    "                        value = write_read(result)\n",
    "                        nval=1\n",
    "                    elif(result!='n'): #will make the motion continues even if the hand is shown once\n",
    "                        print(str(value)+\" \"+str(result))\n",
    "                        value = write_read(result)\n",
    "                        if oldresult != result:\n",
    "                            oldresult=result\n",
    "                            print(str(value)+\" \"+str(oldresult))\n",
    "                            value = write_read(oldresult)\n",
    "                    elif(result=='n' and nval>=1): \n",
    "                        print(str(value)+\" \"+str(oldresult))\n",
    "                        value = write_read(oldresult)\n",
    "                else:\n",
    "                    print(\"Low accuracy\")\n",
    "                    #print(str(value)+\" \"+str(result))\n",
    "                    #value = write_read(result)                                  \n",
    "                    #oldresult = 'Gesture Recognize as : '+str(result)\n",
    "                    cv2.putText(clone, 'Gesture Recognize as : '+str(result), (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 255, 255), 2)\n",
    "                    #if oldresult != result:\n",
    "                        #print(\"\")\n",
    "                #else:\n",
    "                    #cv2.putText(clone, oldresult, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 255, 255), 2)\n",
    "                cv2.imshow(\"video frame\", roi)\n",
    "            else:\n",
    "                cv2.putText(clone, 'No Motion', (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 255, 255), 2)\n",
    "        cv2.rectangle(clone, (left, top), (right, bottom), (0,255,0), 2)\n",
    "        num_frames += 1\n",
    "        cv2.imshow(\"Video Feed\", clone)\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b004bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Low accuracy\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Low accuracy\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Low accuracy\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Low accuracy\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "0.99990416 n\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.9999089 none\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.9999132 none\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.99989414 none\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "0.99989414 none\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "0.9998958 none\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.9999014 none\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.99990165 none\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "0.9999999 none\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.9999 none\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.99947256 none\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0.9994603 none\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "0.9999999 none\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.9998411 f\n",
      "1 f\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.9906674 f\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Low accuracy\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Low accuracy\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Low accuracy\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Low accuracy\n"
     ]
    }
   ],
   "source": [
    "webcamPredict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8539e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6d7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
